\documentclass[11pt,a4paper]{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{color}
\usepackage{url}
\usepackage{fancyhdr}
\usepackage{geometry}
\usepackage{makeidx}

\geometry{left=2cm,right=2cm,top=2cm,bottom=2cm}

% Set headheight for fancyhdr
\setlength{\headheight}{14pt}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\leftmark}
\fancyhead[R]{\thepage}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}

% Define Julia language for listings
\lstdefinelanguage{Julia}{
    morekeywords={abstract,break,case,catch,continue,do,else,elseif,end,export,for,function,immutable,import,if,in,macro,module,otherwise,quote,return,switch,type,typealias,using,while},
    morecomment=[l]{\#},
    morecomment=[n]{\#=}{=\#},
    morestring=[s]{"}{"},
    morestring=[m]{'}{'}
}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize\ttfamily,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                   
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2,
    language=Julia
}

\lstset{style=mystyle}

\title{\textbf{OscarAICoder.jl}}
\author{Vinay Wagh}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
OscarAICoder.jl is a Julia package that translates English mathematical statements into Oscar code using various LLM backends. It supports multiple backend configurations including local, remote, GitHub-hosted, and HuggingFace models.
\end{abstract}

\tableofcontents

\section{Introduction}

OscarAICoder.jl is a Julia package designed to bridge the gap between natural language mathematical statements and executable Oscar code. It leverages modern LLM (Large Language Model) technology to understand and translate mathematical concepts expressed in English into equivalent Oscar code.

\section{Installation}

To install OscarAICoder.jl, use the Julia package manager:

\begin{lstlisting}
using Pkg
Pkg.add("OscarAICoder")
\end{lstlisting}

\section{Basic Usage}

The primary function in OscarAICoder.jl is \texttt{process\_statement}, which takes an English mathematical statement and returns the corresponding Oscar code.

\subsection{Mode Configuration}

OscarAICoder.jl supports different modes of operation:

\subsubsection{Training Mode}

Training mode uses a comprehensive template to guide the LLM in generating Oscar code:

\begin{lstlisting}
using OscarAICoder

# Enable training mode
training_mode!(true)

# Process statement in training mode
process_statement("Define a polynomial ring R with variable x over QQ")
# Uses full template with detailed instructions
\end{lstlisting}

\subsubsection{Context Mode}

Context mode maintains conversation history to help generate more accurate and consistent Oscar code:

\begin{lstlisting}
using OscarAICoder

# First statement in context mode
process_statement("Define a polynomial ring R with variable x over QQ")
# Uses normal prompt template

# Subsequent statement
process_statement("Define the polynomial f = x^2 + 1")
# Uses conversation history with clear instructions
\end{lstlisting}

\subsection{Backend Configuration}

OscarAICoder.jl supports multiple backends for generating Oscar code:

\subsubsection{Local Backend}

Configure the local backend with:

\begin{lstlisting}
using OscarAICoder

# Configure local backend
configure_default_backend(
    :local,
    url="http://localhost:11434/api/generate",
    model="qwen2.5-coder"
)
\end{lstlisting}

\subsubsection{HuggingFace Backend}

Configure the HuggingFace backend with:

\begin{lstlisting}
using OscarAICoder

# Configure HuggingFace backend
configure_github_backend(
    api_key="your_api_key",
    model="your_model_name"
)
\end{lstlisting}

\subsection{Dictionary Mode}

The package includes a built-in dictionary of common mathematical statements. You can configure how it's used:

\begin{lstlisting}
using OscarAICoder

# Try dictionary first, then LLM
configure_dictionary_mode(:priority)

# Try LLM first, then dictionary
configure_dictionary_mode(:llm_first)

# Disable dictionary entirely
configure_dictionary_mode(:disabled)
\end{lstlisting}

\subsection{Context Management}

OscarAICoder.jl maintains conversation context to help generate more accurate and consistent Oscar code:

\subsubsection{Context History}

The context history is automatically managed:
\begin{itemize}
    \item Stores conversation history as tuples of (role, text)
    \item Maintains a maximum history length (default: 5 interactions)
    \item Automatically trims older interactions when history exceeds limit
\end{itemize}

\subsubsection{Clearing Context}

You can clear the context at any time:

\begin{lstlisting}
using OscarAICoder

# Clear context for fresh session
process_statement("Define a polynomial ring R with variable x over QQ", clear_context=true)
\end{lstlisting}

\subsection{Code Execution}

Once you have Oscar code, you can execute it using:

\begin{lstlisting}
using OscarAICoder

# Generate Oscar code
oscar_code = process_statement("Define a polynomial ring R with variable x over QQ")

# Execute the code
result = execute_statement(oscar_code)

# Execute with specific output format
result = execute_statement_with_format(oscar_code, output_format=:latex)
\end{lstlisting}

\subsection{Debugging}

Enable debug mode to see detailed information about the processing:

\begin{lstlisting}
using OscarAICoder

# Enable debug mode
debug_mode!(true)

# Process statement with debug output
process_statement("Define a polynomial ring R with variable x over QQ")
\end{lstlisting}

\subsection{Backend Configuration}

OscarAICoder.jl supports multiple backends for generating Oscar code:

\begin{enumerate}
    \item \textbf{Local Backend}: Uses a local LLM server
    \item \textbf{HuggingFace Backend}: Uses HuggingFace models
    \item \textbf{GitHub Backend}: Uses GitHub-hosted models
\end{enumerate}

\subsubsection{Local Backend}

Configure the local backend with:

\begin{lstlisting}
using OscarAICoder

# Configure local backend
configure_default_backend(
    url="http://localhost:11434/api/generate",
    model="llama3.3"
)

# Process a statement
statement = "Define a polynomial ring R with variables x0, x1, x2, and x3 over the rational numbers QQ."
oscar_code = process_statement(statement)
\end{lstlisting}

\subsubsection{HuggingFace Backend}

Configure the HuggingFace backend with:

\begin{lstlisting}
using OscarAICoder

# Configure HuggingFace backend
configure_github_backend(
    api_key="your_api_key",
    model="your_model_name"
)

# Process a statement
statement = "Define an ideal I in R generated by the polynomials x0 and x1."
oscar_code = process_statement(statement)
\end{lstlisting}

\section{Key Features}

\subsection{Polynomial Rings}

OscarAICoder.jl can handle various polynomial ring operations:

\begin{lstlisting}
# Example: Define a polynomial ring
statement = "Define a polynomial ring R with variables x0, x1, x2, and x3 over the rational numbers QQ."
oscar_code = process_statement(statement)

# Output:
# R, (x0, x1, x2, x3) = polynomial_ring(QQ, ["x0", "x1", "x2", "x3"])
\end{lstlisting}

\subsection{Ideals}

The package supports ideal operations including:

\begin{itemize}
    \item Ideal generation
    \item Ideal intersection
    \item Ideal product
    \item Primary decomposition
    \item Associated primes
\end{itemize}

\begin{lstlisting}
# Example: Ideal operations
statement = "Compute the intersection of the ideals (x, y) and (y, z) in QQ[x, y, z] using Groebner bases."
oscar_code = process_statement(statement)

# Output:
# R, x, y, z = polynomial_ring(QQ, ["x", "y", "z"], order="lex")
# I = ideal(R(x), R(y))
# J = ideal(R(y), R(z))
# t = R.gens()[0] * 0 + 1  # A dummy variable
# S, t_var = R.add_variable("t")
# I_lifted = S.ideal(S(x), S(y))
# J_lifted = S.ideal(S(y), S(z))
# IK = I_lifted * S.ideal(S(1 - t)) + J_lifted * S.ideal(S(t))
# gb_IK = groebner_basis(IK, eliminate=[t_var])
# intersection_ideal = gb_IK.contract(R)
# print(intersection_ideal)
\end{lstlisting}

\subsection{Groebner Bases}

Groebner basis computations are supported with various orderings:

\begin{lstlisting}
# Example: Groebner basis computation
statement = "Compute the Groebner basis of the ideal (x^2 + y^2 - 1, x - y) in QQ[x, y] with respect to the lexicographic order."
oscar_code = process_statement(statement)

# Output:
# R, x, y = polynomial_ring(QQ, ["x", "y"], order="lex")
# I = ideal(R(x^2 + y^2 - 1), R(x - y))
# gb = groebner_basis(I)
# print(gb)
\end{lstlisting}

\subsection{Matrix Operations}

The package can handle matrix operations in polynomial rings:

\begin{lstlisting}
# Example: Matrix construction
statement = "Construct a matrix A with elements from R based on given polynomial expressions."
oscar_code = process_statement(statement)

# Output:
# A = matrix(R, [[1, x0, x1, 0, 0], [1, 0, 0, x2, x3]])
\end{lstlisting}

\section{Training Mode}

OscarAICoder.jl includes a training mode for improving its dictionary:

\begin{lstlisting}
using OscarAICoder

# Enable training mode
dict_mode = configure_dictionary_mode(true)

# Add new entries to the dictionary
add_to_dictionary(
    "Define a new mathematical concept",
    "corresponding_oscar_code"
)

# Check if a statement exists in the dictionary
has_in_dictionary("statement_to_check")
\end{lstlisting}

\section{Debugging}

The package includes debugging utilities:

\begin{lstlisting}
using OscarAICoder

# Enable debug mode
debug_mode!(true)

# Print debug messages
debug_print("Debug information")
\end{lstlisting}

\section{Examples}

\subsection{Polynomial Rings}

\begin{lstlisting}
statement = "Define a polynomial ring R with variables x0, x1, x2, and x3 over the rational numbers QQ."
oscar_code = process_statement(statement)
\end{lstlisting}

\subsection{Ideals}

\begin{lstlisting}
statement = "Define an ideal I in R generated by the polynomials x0 and x1."
oscar_code = process_statement(statement)
\end{lstlisting}

\subsection{Matrix Operations}

\begin{lstlisting}
statement = "Construct a matrix A with elements from R based on given polynomial expressions."
oscar_code = process_statement(statement)
\end{lstlisting}

\section{API Reference}

\subsection{Main Functions}

\begin{description}
    \item[\texttt{process\_statement}] Main function to convert English statements to Oscar code
    \item[\texttt{configure\_default\_backend}] Configure the default LLM backend
    \item[\texttt{configure\_dictionary\_mode}] Configure dictionary usage mode
    \item[\texttt{configure\_github\_backend}] Configure GitHub-hosted model backend
    \item[\texttt{execute\_statement}] Execute generated Oscar code
    \item[\texttt{debug\_mode!}] Enable/disable debug mode
    \item[\texttt{debug\_print}] Print debug messages
\end{description}

\subsection{Dictionary Functions}

\begin{description}
    \item[\texttt{add\_to\_dictionary}] Add new entries to the dictionary
    \item[\texttt{has\_in\_dictionary}] Check if a statement exists in the dictionary
    \item[\texttt{get\_from\_dictionary}] Retrieve Oscar code for a statement
\end{description}

\section{Best Practices}

\begin{itemize}
    \item Always start with dictionary mode enabled for common operations
    \item Use training mode to improve the dictionary with new mathematical concepts
    \item Keep debug mode enabled during development for better insights
    \item Regularly update the dictionary with new mathematical patterns
\end{itemize}

\section{Troubleshooting}

\begin{itemize}
    \item If LLM responses are inconsistent, try different backends
    \item If dictionary lookups fail, check if the statement needs to be more specific
    \item If code execution fails, verify the generated Oscar code syntax
\end{itemize}

\end{document}
configure_dictionary_mode(:priority)

# Use only the dictionary
configure_dictionary_mode(:only)

# Never use dictionary
configure_dictionary_mode(:disabled)
\end{lstlisting}

\section{Backend Configuration}

OscarAICoder supports multiple LLM backends. The default backend can be configured using \texttt{configure\_default\_backend}.

\subsection{Local Backend}

The local backend connects to a locally running LLM server (e.g., Ollama):

\begin{lstlisting}
using OscarAICoder

# Configure local backend
configure_default_backend(:local)

# Process a statement
oscar_code = process_statement("Find the roots of x^2 - 5x + 6 = 0")
\end{lstlisting}

\subsection{Remote Backend}

The remote backend connects to a remote LLM server:

\begin{lstlisting}
using OscarAICoder

# Configure remote backend
configure_default_backend(:remote, url="http://server01.mydomain.net:11434")

# Process a statement
oscar_code = process_statement("Find the roots of x^2 - 5x + 6 = 0")
\end{lstlisting}

\subsection{GitHub Backend}

The GitHub backend uses models hosted in GitHub repositories:

\begin{lstlisting}
using OscarAICoder

# Configure GitHub backend
configure_github_backend(
    repo="username/repo",
    token="github_token",
    model="llama2"
)

# Process a statement
oscar_code = process_statement("Find the roots of x^2 - 5x + 6 = 0")
\end{lstlisting}

\section{Examples}

\subsection{Basic Algebra}

\subsubsection{Polynomial Factorization}

\begin{lstlisting}
using OscarAICoder

# Configure dictionary mode
configure_dictionary_mode(:priority)

# Process statement
oscar_code = process_statement("Factor the polynomial x^2 - 5x + 6 over the integers")
\end{lstlisting}

\subsection{Commutative Algebra}

\subsubsection{Ideal Operations}

\begin{lstlisting}
using OscarAICoder

# Configure GitHub backend
configure_github_backend(
    repo="username/repo",
    token="github_token",
    model="llama2"
)

# Process statement
oscar_code = process_statement("Compute the intersection of ideals (x,y) and (y,z) in Q[x,y,z]")
\end{lstlisting}

\subsection{Algebraic Geometry}

\subsubsection{Variety Computation}

\begin{lstlisting}
using OscarAICoder

# Configure dictionary mode
configure_dictionary_mode(:priority)

# Process statement
oscar_code = process_statement("Compute the variety defined by x^2 + y^2 - 1 in Q[x,y]")
\end{lstlisting}

\subsection{Calculus}

\subsubsection{Integration}

\begin{lstlisting}
using OscarAICoder

# Configure local backend
configure_default_backend(:local)

# Process statement
oscar_code = process_statement("Integrate x^2 from 0 to 1")
\end{lstlisting}

\subsection{Linear Algebra}

\subsubsection{Matrix Operations}

\begin{lstlisting}
using OscarAICoder

# Configure dictionary mode
configure_dictionary_mode(:priority)

# Process statement
oscar_code = process_statement("Compute the determinant of matrix [[1,2],[3,4]]")
\end{lstlisting}

\section{Advanced Features}

\subsection{Offline Mode}

You can enable offline mode to use only the local dictionary:

\begin{lstlisting}
using OscarAICoder

# Enable offline mode
configure_offline_mode(true)

# Only dictionary entries will be used
oscar_code = process_statement("Compute the determinant of a 2x2 matrix")
\end{lstlisting}

\section{Testing}

The package includes a comprehensive test suite organized by mathematical area:

\begin{itemize}
    \item \texttt{doc/tst/commutative\_algebra/}
    \item \texttt{doc/tst/algebraic\_geometry/}
    \item \texttt{doc/tst/calculus/}
    \item \texttt{doc/tst/linear\_algebra/}
\end{itemize}

To run the tests, use the \texttt{make test} command:

\begin{lstlisting}[language=bash]
make test
\end{lstlisting}

\section{Contributing}

Contributions to OscarAICoder.jl are welcome! Please see the \texttt{CONTRIBUTING.md} file for guidelines.

\section{License}

OscarAICoder.jl is licensed under the MIT License.

\end{document}



